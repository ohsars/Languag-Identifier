{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75c2e537",
   "metadata": {},
   "source": [
    "## Yoruba Language Detection\n",
    "\n",
    "##### Final Year Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a506afd",
   "metadata": {},
   "source": [
    "### Importing Basic Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e8e4718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94f4f070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Àwọn Ohun-àmúlò ti Awon Akópa Filé</td>\n",
       "      <td>Yoruba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Àwọn ohun-èlò CC ń ṣe ìrànwọ́ nípa wíwá ojútùú...</td>\n",
       "      <td>Yoruba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Àwọn ojúṣe gẹ́gẹ́ bí i alábòójútó</td>\n",
       "      <td>Yoruba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Àwọn Ológun ní àwọn ò ní tẹ̀lé ẹ̀sùn tí àjọ Àg...</td>\n",
       "      <td>Yoruba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Àwọn olólùfẹ́ ikọ̀ agbábọ́ọ̀lù Pleateau united...</td>\n",
       "      <td>Yoruba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Language\n",
       "0                 Àwọn Ohun-àmúlò ti Awon Akópa Filé   Yoruba\n",
       "1  Àwọn ohun-èlò CC ń ṣe ìrànwọ́ nípa wíwá ojútùú...   Yoruba\n",
       "2                  Àwọn ojúṣe gẹ́gẹ́ bí i alábòójútó   Yoruba\n",
       "3  Àwọn Ológun ní àwọn ò ní tẹ̀lé ẹ̀sùn tí àjọ Àg...   Yoruba\n",
       "4  Àwọn olólùfẹ́ ikọ̀ agbábọ́ọ̀lù Pleateau united...   Yoruba"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv('language_detection-second.csv')\n",
    "df = pd.read_csv('aprilDataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33ef374d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number of International Delegates: 5,000                                                                                                                                            7\n",
       "fun                                                                                                                                                                                 6\n",
       "duro                                                                                                                                                                                6\n",
       "mu                                                                                                                                                                                  6\n",
       "ṣe                                                                                                                                                                                  6\n",
       "                                                                                                                                                                                   ..\n",
       "We are confident that there will be good results from this increased activity in Israel.                                                                                            1\n",
       "We are confident that our brothers and sisters affected by this storm will continue to put their trust in Jehovah, knowing that he will make them firm and strong.—1 Peter 5:10.    1\n",
       "We are confident that our brothers and sisters affected by this fire in Brazil will continue to trust in Jehovah, our “secure refuge in times of distress.”—Psalm 9:9, 10.          1\n",
       "We are confident that Jehovah “is near to all those calling on him” and will continue to help our brothers remain resolute in the face of persecution—Psalm 145:18.                 1\n",
       "ṣe àfihàn ohun táwa Ẹlẹ́rìí Jèhófà gbé ṣe àtohun tó ṣẹlẹ̀ sí wa látọdún yìí wá.                                                                                                     1\n",
       "Name: Text, Length: 26229, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Text\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a221689",
   "metadata": {},
   "source": [
    "### Cleaning up the dataset, using string library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "208af13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387e8160",
   "metadata": {},
   "source": [
    "### A function that cleans the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03b976d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pun(text):\n",
    "    for pun in string.punctuation:\n",
    "        text = text.replace(pun,\"\")\n",
    "    text = text.lower()\n",
    "    return(text)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9700149d",
   "metadata": {},
   "source": [
    "### Trying out the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "124b7f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nature can refer to the phenomena of the 44 physical'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_pun('\"Nature can refer to the phenomena of the: 44##@! physical@.\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89336dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lílo àkàbà — ǹjẹ́ o máa ń ṣe àyẹ̀wò wọ̀nyí tó lè dáàbò bò ẹ́ re'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_pun('\"lílo àkàbà — ǹjẹ́ o máa ń ṣe àyẹ̀wò wọ̀nyí tó lè dáàbò bò ẹ́,? re\"') # => Working wellwith yoruba alphabets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83f9798",
   "metadata": {},
   "source": [
    "### Applying the Function on our Dataset\n",
    "\n",
    "###### This removes every punctuation in the dataset and converts to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "983713e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(remove_pun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a6d2348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>àwọn ohunàmúlò ti awon akópa filé</td>\n",
       "      <td>Yoruba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>àwọn ohunèlò cc ń ṣe ìrànwọ́ nípa wíwá ojútùú ...</td>\n",
       "      <td>Yoruba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>àwọn ojúṣe gẹ́gẹ́ bí i alábòójútó</td>\n",
       "      <td>Yoruba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>àwọn ológun ní àwọn ò ní tẹ̀lé ẹ̀sùn tí àjọ àg...</td>\n",
       "      <td>Yoruba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>àwọn olólùfẹ́ ikọ̀ agbábọ́ọ̀lù pleateau united...</td>\n",
       "      <td>Yoruba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Language\n",
       "0                  àwọn ohunàmúlò ti awon akópa filé   Yoruba\n",
       "1  àwọn ohunèlò cc ń ṣe ìrànwọ́ nípa wíwá ojútùú ...   Yoruba\n",
       "2                  àwọn ojúṣe gẹ́gẹ́ bí i alábòójútó   Yoruba\n",
       "3  àwọn ológun ní àwọn ò ní tẹ̀lé ẹ̀sùn tí àjọ àg...   Yoruba\n",
       "4  àwọn olólùfẹ́ ikọ̀ agbábọ́ọ̀lù pleateau united...   Yoruba"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55d9c306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26775, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb8557f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Yoruba\n",
       "1        Yoruba\n",
       "2        Yoruba\n",
       "3        Yoruba\n",
       "4        Yoruba\n",
       "          ...  \n",
       "26770    Yoruba\n",
       "26771    Yoruba\n",
       "26772    Yoruba\n",
       "26773    Yoruba\n",
       "26774    Yoruba\n",
       "Name: Language, Length: 26775, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Language\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c6a29e",
   "metadata": {},
   "source": [
    "### Dividing datasets to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2a2e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c112af24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Yoruba\n",
       "1        Yoruba\n",
       "2        Yoruba\n",
       "3        Yoruba\n",
       "4        Yoruba\n",
       "          ...  \n",
       "26770    Yoruba\n",
       "26771    Yoruba\n",
       "26772    Yoruba\n",
       "26773    Yoruba\n",
       "26774    Yoruba\n",
       "Name: Language, Length: 26775, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,0] # => Assigning the Texts to X\n",
    "y =df.iloc[:,1] # => Assigning the Language Column\n",
    "# X\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029adfe0",
   "metadata": {},
   "source": [
    "### Assigning test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b32cce0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8669                             total number baptized 476\n",
       " 17748                           lọ iwájú bíi ìṣẹjú àáyá 10\n",
       " 1277     anesthesia machine multiparameter monitor oper...\n",
       " 9064                  we put the government under pressure\n",
       " 15093    agbábọ́ọ̀lù mọ́kànlá ọ̀hún uzoho shehu trooste...\n",
       "                                ...                        \n",
       " 26017                                               itọju \n",
       " 13805    les créateurs d’algorithmes ne sont plus en me...\n",
       " 12008    as david rothenburg writes the beautiful is th...\n",
       " 13625    dans les pays pauvres là où le livre est rare ...\n",
       " 1652     both of these pieces of information can identi...\n",
       " Name: Text, Length: 21420, dtype: object,\n",
       " 23885    ọ̀pọ̀ èèyàn ló mọ̀ pé wọn ò lọ́wọ́ sí ìpẹ̀yàru...\n",
       " 10950                                                 him \n",
       " 10085                                            abstract \n",
       " 9903     “i urge our fans to stand behind the team to f...\n",
       " 21990    ìwé christianity and genocide in rwanda sọ pé ...\n",
       "                                ...                        \n",
       " 25585    akinwumi sorinmade ni orúkọ tí aroke ń lo ni i...\n",
       " 14190    abẹnugan ilé ìgbìmọ̀ asojú ìpínlẹ̀ sokoto amin...\n",
       " 10618                                             tactics \n",
       " 11160                                                 ran \n",
       " 15660    bí a bá sọ́ pé ẹyẹ ni yó jẹ ojú ẹni bí a rí tí...\n",
       " Name: Text, Length: 5355, dtype: object,\n",
       " 8669     Not Yoruba\n",
       " 17748        Yoruba\n",
       " 1277     Not Yoruba\n",
       " 9064     Not Yoruba\n",
       " 15093        Yoruba\n",
       "             ...    \n",
       " 26017        Yoruba\n",
       " 13805        French\n",
       " 12008    Not Yoruba\n",
       " 13625        French\n",
       " 1652     Not Yoruba\n",
       " Name: Language, Length: 21420, dtype: object,\n",
       " 23885        Yoruba\n",
       " 10950    Not Yoruba\n",
       " 10085    Not Yoruba\n",
       " 9903     Not Yoruba\n",
       " 21990        Yoruba\n",
       "             ...    \n",
       " 25585        Yoruba\n",
       " 14190        Yoruba\n",
       " 10618    Not Yoruba\n",
       " 11160    Not Yoruba\n",
       " 15660        Yoruba\n",
       " Name: Language, Length: 5355, dtype: object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size =.2, stratify=y)\n",
    "X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff415889",
   "metadata": {},
   "source": [
    "### Converting values to computer understandable version = Encoding\n",
    "\n",
    "###### Vectorizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "913591cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3b8cee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='char', ngram_range=(1, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = feature_extraction.text.TfidfVectorizer(ngram_range=(1,2),analyzer='char') # Unigrams and bigrams\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b18a9ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import pipeline\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b0cf68",
   "metadata": {},
   "source": [
    "### Pipeline: creating a complete flow of functions (converting to vector and training) multpile steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e806091",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe = pipeline.Pipeline([('vec',vec),('clf', linear_model.LogisticRegression())])\n",
    "# model_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c17f636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec', TfidfVectorizer(analyzer='char', ngram_range=(1, 2))),\n",
       "                ('clf', LogisticRegression())])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54480ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['French', 'Not Yoruba', 'Yoruba'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ee05bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_val = model_pipe.predict(X_test)\n",
    "# predict_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbf4b91",
   "metadata": {},
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a6c7f6",
   "metadata": {},
   "source": [
    "# Trying other Models (Multinomial NB, Random Forest, KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2389b",
   "metadata": {},
   "source": [
    "# ................................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de70ef3d",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d19a0a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes classifier\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# load the dataset\n",
    "df2 = pd.read_csv('aprilDataset.csv')\n",
    "\n",
    "# Preprocess the text by converting to a bag-of-words representation\n",
    "vectorizer = TfidfVectorizer()\n",
    "A = vectorizer.fit_transform(df2['Text'])\n",
    "\n",
    "# Convert the target labels to numerical values\n",
    "b = pd.factorize(df2['Language'])[0]\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "A_train, A_val, b_train, b_val = train_test_split(A, b, test_size=0.2, random_state=42, stratify=b)\n",
    "\n",
    "\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "mnb.fit(A_train, b_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ef29401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the performance\n",
    "\n",
    "# Predict the language for each sample in the validation set\n",
    "b_pred = mnb.predict(A_val)\n",
    "\n",
    "# Compute the accuracy of the predictions\n",
    "accuracy = accuracy_score(b_val, b_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7df2e84",
   "metadata": {},
   "source": [
    "### Multinomial NB Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00a25bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The language of \"My name is Damilola\" is Not Yoruba\n"
     ]
    }
   ],
   "source": [
    "# Predict the language of new text\n",
    "sampleText = 'My name is Damilola'\n",
    "\n",
    "NBlanguage_label = mnb.predict(vectorizer.transform([sampleText]))\n",
    "NBlanguage = pd.Categorical.from_codes(NBlanguage_label, df2['Language'].unique())[0]\n",
    "print(f'The language of \"{sampleText}\" is {NBlanguage}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9065cd14",
   "metadata": {},
   "source": [
    "# ................................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0912c32",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bc69c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.94%\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# load and preprocess the dataset\n",
    "df3 = pd.read_csv('aprilDataset.csv')\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3), analyzer=\"char\")\n",
    "C = vectorizer.fit_transform(df3[\"Text\"])\n",
    "d = df[\"Language\"]\n",
    "\n",
    "# train the Random Forest model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(C, d)\n",
    "\n",
    "# preprocess your input\n",
    "# my_input_vectorized = vectorizer.transform([my_input])\n",
    "\n",
    "# use your model to make predictions\n",
    "# predicted_language = rf.predict(my_input_vectorized)\n",
    "\n",
    "# print the predicted output\n",
    "# print(\"the language is\" ,(predicted_language))\n",
    "\n",
    "# Make predictions on the testing data\n",
    "predictions = rf.predict(C)\n",
    "\n",
    "# Calculate the accuracy score of the random forest classifier\n",
    "accuracy = accuracy_score(d, predictions)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9efdfe",
   "metadata": {},
   "source": [
    "### RF RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ba0a6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the language is ['Yoruba']\n"
     ]
    }
   ],
   "source": [
    "my_input2 = \"Mofẹ́ pààrọ̀ gílóòbù iná\"\n",
    "\n",
    "# Sample text = Let's Party hard tonight, Mofẹ́ pààrọ̀ gílóòbù iná, My father is the cousin to England's present Queen\n",
    "\n",
    "my_input_vectorized2 = vectorizer.transform([my_input2]) #= Preprocessing\n",
    "predicted_language2 = rf.predict(my_input_vectorized2) #= using model\n",
    "\n",
    "print(\"the language is\" ,(predicted_language2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d5e5e4",
   "metadata": {},
   "source": [
    "# ................................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc56c4f",
   "metadata": {},
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "raw",
   "id": "16d12eb0",
   "metadata": {},
   "source": [
    "# import the necessary libraries\n",
    "import tensorflow as tf\n",
    "\n",
    "# load and preprocess your input text\n",
    "my_text = \"Bonjour tout le monde!\"\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts([my_text])\n",
    "input_sequence = tokenizer.texts_to_sequences([my_text])\n",
    "input_data = tf.keras.preprocessing.sequence.pad_sequences(input_sequence, maxlen=50)\n",
    "\n",
    "# load your trained model\n",
    "model = tf.keras.models.load_model(\"model.pkl\")\n",
    "\n",
    "# use your model to make predictions\n",
    "predicted_language = model.predict(input_data)\n",
    "\n",
    "# print the predicted output\n",
    "print(predicted_language)\n",
    "\n",
    "Error: Tensorflow Library not fully installed, giving OS issues... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbbebe0",
   "metadata": {},
   "source": [
    "# ................................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a599dd5e",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbour model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dacdd4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Horsars Marvel\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55\n"
     ]
    }
   ],
   "source": [
    "# import the important libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load the text data into a pandas DataFrame\n",
    "dataKNN = pd.read_csv('aprilDataset.csv')\n",
    "\n",
    "# Preprocess the text by converting to a bag-of-words representation\n",
    "vectorizer1 = TfidfVectorizer()\n",
    "E = vectorizer1.fit_transform(dataKNN['Text'])\n",
    "\n",
    "# Convert the target labels to numerical values\n",
    "f = pd.factorize(dataKNN['Language'])[0]\n",
    "\n",
    "# Split to test, train \n",
    "E_train, E_val, f_train, f_val = train_test_split(E, f, test_size=0.2, stratify=y)\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn2 = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn2.fit(E_train, f_train)\n",
    "\n",
    "# Predict the language for each sample in the validation set\n",
    "f_pred = knn2.predict(E_val)\n",
    "\n",
    "\n",
    "\n",
    "# Was having issues witht the transform(), i had to transform the text to be predicted\n",
    "# checking the size of the trained data\n",
    "\n",
    "# print(E_train.shape)\n",
    "# print(E_val.shape)\n",
    "\n",
    "\n",
    "# Create a dictionary that maps numerical labels to language names\n",
    "label_to_language = {0: 'Yoruba', 1: 'Not Yoruba'}\n",
    "\n",
    "\n",
    "# Compute the accuracy of the predictions\n",
    "accuracy = sum(f_pred == f_val) / len(f_val)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2628c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary that maps numerical labels to language names\n",
    "label_to_language = {0: 'Yoruba', 1: 'Not Yoruba', 2:'Not Yoruba'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2a9c57",
   "metadata": {},
   "source": [
    "### KNN RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35a5ecb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The language of \"Mofẹ́\" is Yoruba\n"
     ]
    }
   ],
   "source": [
    "# Predict the language of new text\n",
    "predictText = 'Mofẹ́'\n",
    "\n",
    "# sample text = My father is the cousin to England's present Queen, Bonjour, comment allez-vous?\n",
    "\n",
    "language_label = knn2.predict(vectorizer1.transform([predictText]))[0]\n",
    "mainLanguage = label_to_language[language_label]\n",
    "print(f'The language of \"{predictText}\" is {mainLanguage}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3426b0",
   "metadata": {},
   "source": [
    "# ................................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971f80c3",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de0885",
   "metadata": {},
   "source": [
    "\n",
    "### Calculating the Accuracy  of the main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3678b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "483e41e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.99159663865547\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {metrics.accuracy_score(y_test,predict_val)*100}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd35698",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4eb3f691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 186,   16,    1],\n",
       "       [   1, 2615,   16],\n",
       "       [   0,   20, 2500]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test,predict_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d45e1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yoruba'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.predict(['ooni']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "906922a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Not Yoruba'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.predict(['spy']) # => Wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b4e7c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if model_pipe.predict(['ílóòbù iná tó wà']) != 'Yoruba' or model_pipe.predict(['Marvelous']) != 'English':\n",
    "#     error = ('Error: Not a yoruba or English text')\n",
    "#     print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fc03ff",
   "metadata": {},
   "source": [
    "### Saving as a pickle file\n",
    "\n",
    "##### to be used on the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03353197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a679f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_file = open('model.pckl', 'wb')\n",
    "new_file = open('model.pkl', 'wb')\n",
    "pickle.dump(model_pipe,new_file)\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce564d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c131222",
   "metadata": {},
   "source": [
    "## Thank You!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
