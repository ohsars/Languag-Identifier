{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yoruba Language Detection\n",
    "\n",
    "##### Final Year Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Basic Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lílo àkàbà ǹjẹ́ o máa ń ṣe àyẹ̀wò wọ̀nyí tó l...</td>\n",
       "      <td>Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paul fẹ́ pààrọ̀ gílóòbù iná tó wà lóde ilé ẹ̀</td>\n",
       "      <td>Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abbreviate</td>\n",
       "      <td>Not Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abbreviation</td>\n",
       "      <td>Not Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ink</td>\n",
       "      <td>Not Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4287</th>\n",
       "      <td>nose</td>\n",
       "      <td>Not Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4288</th>\n",
       "      <td>plural</td>\n",
       "      <td>Not Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4289</th>\n",
       "      <td>anger</td>\n",
       "      <td>Not Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4290</th>\n",
       "      <td>claim</td>\n",
       "      <td>Not Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4291</th>\n",
       "      <td>continent</td>\n",
       "      <td>Not Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text    Language Unnamed: 2\n",
       "0     lílo àkàbà ǹjẹ́ o máa ń ṣe àyẹ̀wò wọ̀nyí tó l...      Yoruba        NaN\n",
       "1        paul fẹ́ pààrọ̀ gílóòbù iná tó wà lóde ilé ẹ̀       Yoruba        NaN\n",
       "2                                           abbreviate   Not Yoruba        NaN\n",
       "3                                         abbreviation   Not Yoruba        NaN\n",
       "4                                                  ink   Not Yoruba        NaN\n",
       "...                                                 ...         ...        ...\n",
       "4287                                              nose   Not Yoruba        NaN\n",
       "4288                                            plural   Not Yoruba        NaN\n",
       "4289                                             anger   Not Yoruba        NaN\n",
       "4290                                             claim   Not Yoruba        NaN\n",
       "4291                                         continent   Not Yoruba        NaN\n",
       "\n",
       "[4292 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./language_detection-second.csv')\n",
    "df.head()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ṣe            6\n",
       "mu            6\n",
       "duro          6\n",
       "ni            6\n",
       "fun           5\n",
       "             ..\n",
       "ìwọṣọ         1\n",
       "òjò dídì      1\n",
       "yìnyín        1\n",
       "irun ara      1\n",
       "continent     1\n",
       "Name: Text, Length: 4069, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Text\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up the dataset, using string library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function that cleans the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pun(text):\n",
    "    for pun in string.punctuation:\n",
    "        text = text.replace(pun,\"\")\n",
    "    text = text.lower()\n",
    "    return(text)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nature can refer to the phenomena of the 44 physical'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_pun('\"Nature can refer to the phenomena of the: 44##@! physical@.\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lílo àkàbà — ǹjẹ́ o máa ń ṣe àyẹ̀wò wọ̀nyí tó lè dáàbò bò ẹ́ re'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_pun('\"lílo àkàbà — ǹjẹ́ o máa ń ṣe àyẹ̀wò wọ̀nyí tó lè dáàbò bò ẹ́,? re\"') # => Working wellwith yoruba alphabets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Function on our Dataset\n",
    "\n",
    "###### This removes every punctuation in the dataset and converts to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(remove_pun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lílo àkàbà ǹjẹ́ o máa ń ṣe àyẹ̀wò wọ̀nyí tó l...</td>\n",
       "      <td>Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paul fẹ́ pààrọ̀ gílóòbù iná tó wà lóde ilé ẹ̀</td>\n",
       "      <td>Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abbreviate</td>\n",
       "      <td>Not Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abbreviation</td>\n",
       "      <td>Not Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ink</td>\n",
       "      <td>Not Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text    Language Unnamed: 2\n",
       "0  lílo àkàbà ǹjẹ́ o máa ń ṣe àyẹ̀wò wọ̀nyí tó l...      Yoruba        NaN\n",
       "1     paul fẹ́ pààrọ̀ gílóòbù iná tó wà lóde ilé ẹ̀       Yoruba        NaN\n",
       "2                                        abbreviate   Not Yoruba        NaN\n",
       "3                                      abbreviation   Not Yoruba        NaN\n",
       "4                                               ink   Not Yoruba        NaN"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4292, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing datasets to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           Yoruba\n",
       "1           Yoruba\n",
       "2       Not Yoruba\n",
       "3       Not Yoruba\n",
       "4       Not Yoruba\n",
       "           ...    \n",
       "4287    Not Yoruba\n",
       "4288    Not Yoruba\n",
       "4289    Not Yoruba\n",
       "4290    Not Yoruba\n",
       "4291    Not Yoruba\n",
       "Name: Language, Length: 4292, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,0] # => Assigning the Texts to X\n",
    "y =df.iloc[:,1] # => Assigning the Language Column\n",
    "# X\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352          groin \n",
       " 819     lòlọ́nàìtọ́\n",
       " 3801       perhaps \n",
       " 3121         iberu \n",
       " 1895           egbò\n",
       "            ...     \n",
       " 3479          over \n",
       " 2534         mẹrin \n",
       " 3631         south \n",
       " 431      ice cream \n",
       " 1571          púpọ̀\n",
       " Name: Text, Length: 3433, dtype: object,\n",
       " 4040        view \n",
       " 3902     trouble \n",
       " 3399        made \n",
       " 4097    neighbor \n",
       " 3122         oju \n",
       "           ...    \n",
       " 1699         iyìn\n",
       " 1004         yàrá\n",
       " 1729        ìmúye\n",
       " 277          eel \n",
       " 122       absent \n",
       " Name: Text, Length: 859, dtype: object,\n",
       " 352     Not Yoruba\n",
       " 819         Yoruba\n",
       " 3801    Not Yoruba\n",
       " 3121        Yoruba\n",
       " 1895        Yoruba\n",
       "            ...    \n",
       " 3479    Not Yoruba\n",
       " 2534        Yoruba\n",
       " 3631    Not Yoruba\n",
       " 431     Not Yoruba\n",
       " 1571        Yoruba\n",
       " Name: Language, Length: 3433, dtype: object,\n",
       " 4040    Not Yoruba\n",
       " 3902    Not Yoruba\n",
       " 3399    Not Yoruba\n",
       " 4097    Not Yoruba\n",
       " 3122        Yoruba\n",
       "            ...    \n",
       " 1699        Yoruba\n",
       " 1004        Yoruba\n",
       " 1729        Yoruba\n",
       " 277     Not Yoruba\n",
       " 122     Not Yoruba\n",
       " Name: Language, Length: 859, dtype: object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = .2)\n",
    "X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting values to computer understandable version = Encoding\n",
    "\n",
    "###### Vectorizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='char', ngram_range=(1, 2))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = feature_extraction.text.TfidfVectorizer(ngram_range=(1,2),analyzer='char') # Unigrams and bigrams\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import pipeline\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline: creating a complete flow of functions (converting to vector and training) multpile steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe = pipeline.Pipeline([('vec',vec),('clf', linear_model.LogisticRegression())])\n",
    "# model_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec', TfidfVectorizer(analyzer='char', ngram_range=(1, 2))),\n",
       "                ('clf', LogisticRegression())])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Not Yoruba', 'Yoruba'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_val = model_pipe.predict(X_test)\n",
    "# predict_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying other Models (Multinomial NB, Random Forest, KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ................................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes classifier\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# load the dataset\n",
    "df2 = pd.read_csv(\"language_detection-second.csv\")\n",
    "\n",
    "# Preprocess the text by converting to a bag-of-words representation\n",
    "vectorizer = TfidfVectorizer()\n",
    "A = vectorizer.fit_transform(df2['Text'])\n",
    "\n",
    "# Convert the target labels to numerical values\n",
    "b = pd.factorize(df2['Language'])[0]\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "A_train, A_val, b_train, b_val = train_test_split(A, b, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "mnb.fit(A_train, b_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the performance\n",
    "\n",
    "# Predict the language for each sample in the validation set\n",
    "b_pred = mnb.predict(A_val)\n",
    "\n",
    "# Compute the accuracy of the predictions\n",
    "accuracy = accuracy_score(b_val, b_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The language of \"My name is Damilola\" is Not Yoruba\n"
     ]
    }
   ],
   "source": [
    "# Predict the language of new text\n",
    "sampleText = 'My name is Damilola'\n",
    "\n",
    "NBlanguage_label = mnb.predict(vectorizer.transform([sampleText]))\n",
    "NBlanguage = pd.Categorical.from_codes(NBlanguage_label, df2['Language'].unique())[0]\n",
    "print(f'The language of \"{sampleText}\" is {NBlanguage}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ................................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.86%\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# load and preprocess the dataset\n",
    "df3 = pd.read_csv(\"language_detection-second.csv\")\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3), analyzer=\"char\")\n",
    "C = vectorizer.fit_transform(df3[\"Text\"])\n",
    "d = df[\"Language\"]\n",
    "\n",
    "# train the Random Forest model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(C, d)\n",
    "\n",
    "# preprocess your input\n",
    "# my_input_vectorized = vectorizer.transform([my_input])\n",
    "\n",
    "# use your model to make predictions\n",
    "# predicted_language = rf.predict(my_input_vectorized)\n",
    "\n",
    "# print the predicted output\n",
    "# print(\"the language is\" ,(predicted_language))\n",
    "\n",
    "# Make predictions on the testing data\n",
    "predictions = rf.predict(C)\n",
    "\n",
    "# Calculate the accuracy score of the random forest classifier\n",
    "accuracy = accuracy_score(d, predictions)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the language is ['Yoruba']\n"
     ]
    }
   ],
   "source": [
    "my_input2 = \"Mofẹ́ pààrọ̀ gílóòbù iná\"\n",
    "\n",
    "# Sample text = Let's Party hard tonight, Mofẹ́ pààrọ̀ gílóòbù iná, My father is the cousin to England's present Queen\n",
    "\n",
    "my_input_vectorized2 = vectorizer.transform([my_input2]) #= Preprocessing\n",
    "predicted_language2 = rf.predict(my_input_vectorized2) #= using model\n",
    "\n",
    "print(\"the language is\" ,(predicted_language2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ................................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import the necessary libraries\n",
    "import tensorflow as tf\n",
    "\n",
    "# load and preprocess your input text\n",
    "my_text = \"Bonjour tout le monde!\"\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts([my_text])\n",
    "input_sequence = tokenizer.texts_to_sequences([my_text])\n",
    "input_data = tf.keras.preprocessing.sequence.pad_sequences(input_sequence, maxlen=50)\n",
    "\n",
    "# load your trained model\n",
    "model = tf.keras.models.load_model(\"model.pkl\")\n",
    "\n",
    "# use your model to make predictions\n",
    "predicted_language = model.predict(input_data)\n",
    "\n",
    "# print the predicted output\n",
    "print(predicted_language)\n",
    "\n",
    "Error: Tensorflow Library not fully installed, giving OS issues... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ................................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbour model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Horsars Marvel\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.64\n"
     ]
    }
   ],
   "source": [
    "# import the important libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load the text data into a pandas DataFrame\n",
    "dataKNN = pd.read_csv('language_detection-second.csv')\n",
    "\n",
    "# Preprocess the text by converting to a bag-of-words representation\n",
    "vectorizer1 = TfidfVectorizer()\n",
    "E = vectorizer1.fit_transform(dataKNN['Text'])\n",
    "\n",
    "# Convert the target labels to numerical values\n",
    "f = pd.factorize(dataKNN['Language'])[0]\n",
    "\n",
    "# Split to test, train \n",
    "E_train, E_val, f_train, f_val = train_test_split(E, f, test_size=0.2, stratify=y)\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn2 = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn2.fit(E_train, f_train)\n",
    "\n",
    "# Predict the language for each sample in the validation set\n",
    "f_pred = knn2.predict(E_val)\n",
    "\n",
    "\n",
    "\n",
    "# Was having issues witht the transform(), i had to transform the text to be predicted\n",
    "# checking the size of the trained data\n",
    "\n",
    "# print(E_train.shape)\n",
    "# print(E_val.shape)\n",
    "\n",
    "\n",
    "# Create a dictionary that maps numerical labels to language names\n",
    "label_to_language = {0: 'Yoruba', 1: 'Not Yoruba'}\n",
    "\n",
    "\n",
    "# Compute the accuracy of the predictions\n",
    "accuracy = sum(f_pred == f_val) / len(f_val)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The language of \"Mofẹ́ pààrọ̀ gílóòbù iná\" is Yoruba\n"
     ]
    }
   ],
   "source": [
    "# Predict the language of new text\n",
    "predictText = 'Mofẹ́ pààrọ̀ gílóòbù iná'\n",
    "\n",
    "# sample text = My father is the cousin to England's present Queen, Bonjour, comment allez-vous?\n",
    "\n",
    "language_label = knn2.predict(vectorizer1.transform([predictText]))[0]\n",
    "mainLanguage = label_to_language[language_label]\n",
    "print(f'The language of \"{predictText}\" is {mainLanguage}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ................................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Calculating the Accuracy  of the main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.78812572759023\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {metrics.accuracy_score(y_test,predict_val)*100}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[323,  11],\n",
       "       [  8, 517]], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test,predict_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Not Yoruba'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.predict(['My name is osas']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yoruba'], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.predict(['pin']) # => Wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if model_pipe.predict(['ílóòbù iná tó wà']) != 'Yoruba' or model_pipe.predict(['Marvelous']) != 'English':\n",
    "#     error = ('Error: Not a yoruba or English text')\n",
    "#     print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving as a pickle file\n",
    "\n",
    "##### to be used on the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_file = open('model.pckl', 'wb')\n",
    "new_file = open('model.pkl', 'wb')\n",
    "pickle.dump(model_pipe,new_file)\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank You!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
