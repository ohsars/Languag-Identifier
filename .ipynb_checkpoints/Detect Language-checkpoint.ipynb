{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75c2e537",
   "metadata": {},
   "source": [
    "## Yoruba Language Detection\n",
    "\n",
    "##### Final Year Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a506afd",
   "metadata": {},
   "source": [
    "### Importing Basic Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e8e4718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94f4f070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lílo àkàbà ǹjẹ́ o máa ń ṣe àyẹ̀wò wọ̀nyí tó l...</td>\n",
       "      <td>Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paul fẹ́ pààrọ̀ gílóòbù iná tó wà lóde ilé ẹ̀</td>\n",
       "      <td>Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abbreviate</td>\n",
       "      <td>Not Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abbreviation</td>\n",
       "      <td>Not Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abdomen</td>\n",
       "      <td>Not Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text    Language Unnamed: 2\n",
       "0  lílo àkàbà ǹjẹ́ o máa ń ṣe àyẹ̀wò wọ̀nyí tó l...      Yoruba        NaN\n",
       "1     paul fẹ́ pààrọ̀ gílóòbù iná tó wà lóde ilé ẹ̀       Yoruba        NaN\n",
       "2                                        abbreviate   Not Yoruba        NaN\n",
       "3                                      abbreviation   Not Yoruba        NaN\n",
       "4                                           abdomen   Not Yoruba        NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('language_detection-second.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33ef374d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yoruba        2572\n",
       "Not Yoruba    1713\n",
       "Name: Language, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Language\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a221689",
   "metadata": {},
   "source": [
    "### Cleaning up the dataset, using string library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "208af13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387e8160",
   "metadata": {},
   "source": [
    "### A function that cleans the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03b976d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pun(text):\n",
    "    for pun in string.punctuation:\n",
    "        text = text.replace(pun,\"\")\n",
    "    text = text.lower()\n",
    "    return(text)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9700149d",
   "metadata": {},
   "source": [
    "### Trying out the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "124b7f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nature can refer to the phenomena of the 44 physical'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_pun('\"Nature can refer to the phenomena of the: 44##@! physical@.\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89336dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lílo àkàbà — ǹjẹ́ o máa ń ṣe àyẹ̀wò wọ̀nyí tó lè dáàbò bò ẹ́ re'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_pun('\"lílo àkàbà — ǹjẹ́ o máa ń ṣe àyẹ̀wò wọ̀nyí tó lè dáàbò bò ẹ́,? re\"') # => Working wellwith yoruba alphabets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83f9798",
   "metadata": {},
   "source": [
    "### Applying the Function on our Dataset\n",
    "\n",
    "###### This removes every punctuation in the dataset and converts to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "983713e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(remove_pun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a6d2348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lílo àkàbà ǹjẹ́ o máa ń ṣe àyẹ̀wò wọ̀nyí tó l...</td>\n",
       "      <td>Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paul fẹ́ pààrọ̀ gílóòbù iná tó wà lóde ilé ẹ̀</td>\n",
       "      <td>Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abbreviate</td>\n",
       "      <td>Not Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abbreviation</td>\n",
       "      <td>Not Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abdomen</td>\n",
       "      <td>Not Yoruba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text    Language Unnamed: 2\n",
       "0  lílo àkàbà ǹjẹ́ o máa ń ṣe àyẹ̀wò wọ̀nyí tó l...      Yoruba        NaN\n",
       "1     paul fẹ́ pààrọ̀ gílóòbù iná tó wà lóde ilé ẹ̀       Yoruba        NaN\n",
       "2                                        abbreviate   Not Yoruba        NaN\n",
       "3                                      abbreviation   Not Yoruba        NaN\n",
       "4                                           abdomen   Not Yoruba        NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55d9c306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4285, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c6a29e",
   "metadata": {},
   "source": [
    "### Dividing datasets to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2a2e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c112af24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           Yoruba\n",
       "1           Yoruba\n",
       "2       Not Yoruba\n",
       "3       Not Yoruba\n",
       "4       Not Yoruba\n",
       "           ...    \n",
       "4280    Not Yoruba\n",
       "4281    Not Yoruba\n",
       "4282    Not Yoruba\n",
       "4283    Not Yoruba\n",
       "4284    Not Yoruba\n",
       "Name: Language, Length: 4285, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,0] # => Assigning the Texts to X\n",
    "y =df.iloc[:,1] # => Assigning the Language Column\n",
    "# X\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029adfe0",
   "metadata": {},
   "source": [
    "### Assigning test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b32cce0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3115          oju \n",
       " 2081          tìrẹ\n",
       " 3855       winter \n",
       " 4093       rather \n",
       " 2755         dara \n",
       "            ...    \n",
       " 3779         rule \n",
       " 1072    àárọ̀ kùtù\n",
       " 4032      natural \n",
       " 3114        iberu \n",
       " 1063         ẹ̀kọ́\n",
       " Name: Text, Length: 3428, dtype: object,\n",
       " 1566                                           ọ̀pọ̀lọpọ̀\n",
       " 1917                                           yunifásítì\n",
       " 3020                                             orundun \n",
       " 2196    ẹ wo ohun táwọn òṣèré tíàtà ń sọ nípa alabi tó...\n",
       " 1725                                           ti ẹlẹ́rìí\n",
       "                               ...                        \n",
       " 2159    yinka ayefele fi orin ẹ ṣeun sẹ́nu lórí ilé or...\n",
       " 4131                                             current \n",
       " 4256                                                born \n",
       " 759                                             àkọ̀mọ̀nà\n",
       " 878                                     fi ẹ̀rọ tì síwájú\n",
       " Name: Text, Length: 857, dtype: object,\n",
       " 3115        Yoruba\n",
       " 2081        Yoruba\n",
       " 3855    Not Yoruba\n",
       " 4093    Not Yoruba\n",
       " 2755        Yoruba\n",
       "            ...    \n",
       " 3779    Not Yoruba\n",
       " 1072        Yoruba\n",
       " 4032    Not Yoruba\n",
       " 3114        Yoruba\n",
       " 1063        Yoruba\n",
       " Name: Language, Length: 3428, dtype: object,\n",
       " 1566        Yoruba\n",
       " 1917        Yoruba\n",
       " 3020        Yoruba\n",
       " 2196        Yoruba\n",
       " 1725        Yoruba\n",
       "            ...    \n",
       " 2159        Yoruba\n",
       " 4131    Not Yoruba\n",
       " 4256    Not Yoruba\n",
       " 759         Yoruba\n",
       " 878         Yoruba\n",
       " Name: Language, Length: 857, dtype: object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = .2, stratify=y)\n",
    "X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff415889",
   "metadata": {},
   "source": [
    "### Converting values to computer understandable version = Encoding\n",
    "\n",
    "###### Vectorizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "913591cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3b8cee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='char', ngram_range=(1, 2))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = feature_extraction.text.TfidfVectorizer(ngram_range=(1,2),analyzer='char') # Unigrams and bigrams\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b18a9ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import pipeline\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b0cf68",
   "metadata": {},
   "source": [
    "### Pipeline: creating a complete flow of functions (converting to vector and training) multpile steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e806091",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe = pipeline.Pipeline([('vec',vec),('clf', linear_model.LogisticRegression())])\n",
    "# model_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c17f636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec', TfidfVectorizer(analyzer='char', ngram_range=(1, 2))),\n",
       "                ('clf', LogisticRegression())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54480ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Not Yoruba', 'Yoruba'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ee05bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_val = model_pipe.predict(X_test)\n",
    "# predict_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbf4b91",
   "metadata": {},
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a6c7f6",
   "metadata": {},
   "source": [
    "# Trying other Models (Multinomial NB, Random Forest, KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2389b",
   "metadata": {},
   "source": [
    "# ................................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de70ef3d",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d19a0a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes classifier\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# load the dataset\n",
    "df2 = pd.read_csv(\"language_detection-second.csv\")\n",
    "\n",
    "# Preprocess the text by converting to a bag-of-words representation\n",
    "vectorizer = TfidfVectorizer()\n",
    "A = vectorizer.fit_transform(df2['Text'])\n",
    "\n",
    "# Convert the target labels to numerical values\n",
    "b = pd.factorize(df2['Language'])[0]\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "A_train, A_val, b_train, b_val = train_test_split(A, b, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "mnb.fit(A_train, b_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ef29401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the performance\n",
    "\n",
    "# Predict the language for each sample in the validation set\n",
    "b_pred = mnb.predict(A_val)\n",
    "\n",
    "# Compute the accuracy of the predictions\n",
    "accuracy = accuracy_score(b_val, b_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7df2e84",
   "metadata": {},
   "source": [
    "### Multinomial NB Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00a25bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The language of \"My name is Damilola\" is Not Yoruba\n"
     ]
    }
   ],
   "source": [
    "# Predict the language of new text\n",
    "sampleText = 'My name is Damilola'\n",
    "\n",
    "NBlanguage_label = mnb.predict(vectorizer.transform([sampleText]))\n",
    "NBlanguage = pd.Categorical.from_codes(NBlanguage_label, df2['Language'].unique())[0]\n",
    "print(f'The language of \"{sampleText}\" is {NBlanguage}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9065cd14",
   "metadata": {},
   "source": [
    "# ................................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0912c32",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bc69c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.86%\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# load and preprocess the dataset\n",
    "df3 = pd.read_csv(\"language_detection-second.csv\")\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3), analyzer=\"char\")\n",
    "C = vectorizer.fit_transform(df3[\"Text\"])\n",
    "d = df[\"Language\"]\n",
    "\n",
    "# train the Random Forest model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(C, d)\n",
    "\n",
    "# preprocess your input\n",
    "# my_input_vectorized = vectorizer.transform([my_input])\n",
    "\n",
    "# use your model to make predictions\n",
    "# predicted_language = rf.predict(my_input_vectorized)\n",
    "\n",
    "# print the predicted output\n",
    "# print(\"the language is\" ,(predicted_language))\n",
    "\n",
    "# Make predictions on the testing data\n",
    "predictions = rf.predict(C)\n",
    "\n",
    "# Calculate the accuracy score of the random forest classifier\n",
    "accuracy = accuracy_score(d, predictions)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9efdfe",
   "metadata": {},
   "source": [
    "### RF RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ba0a6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the language is ['Yoruba']\n"
     ]
    }
   ],
   "source": [
    "my_input2 = \"Mofẹ́ pààrọ̀ gílóòbù iná\"\n",
    "\n",
    "# Sample text = Let's Party hard tonight, Mofẹ́ pààrọ̀ gílóòbù iná, My father is the cousin to England's present Queen\n",
    "\n",
    "my_input_vectorized2 = vectorizer.transform([my_input2]) #= Preprocessing\n",
    "predicted_language2 = rf.predict(my_input_vectorized2) #= using model\n",
    "\n",
    "print(\"the language is\" ,(predicted_language2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d5e5e4",
   "metadata": {},
   "source": [
    "# ................................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc56c4f",
   "metadata": {},
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "raw",
   "id": "16d12eb0",
   "metadata": {},
   "source": [
    "# import the necessary libraries\n",
    "import tensorflow as tf\n",
    "\n",
    "# load and preprocess your input text\n",
    "my_text = \"Bonjour tout le monde!\"\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts([my_text])\n",
    "input_sequence = tokenizer.texts_to_sequences([my_text])\n",
    "input_data = tf.keras.preprocessing.sequence.pad_sequences(input_sequence, maxlen=50)\n",
    "\n",
    "# load your trained model\n",
    "model = tf.keras.models.load_model(\"model.pkl\")\n",
    "\n",
    "# use your model to make predictions\n",
    "predicted_language = model.predict(input_data)\n",
    "\n",
    "# print the predicted output\n",
    "print(predicted_language)\n",
    "\n",
    "Error: Tensorflow Library not fully installed, giving OS issues... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbbebe0",
   "metadata": {},
   "source": [
    "# ................................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a599dd5e",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbour model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dacdd4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Horsars Marvel\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# import the important libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load the text data into a pandas DataFrame\n",
    "dataKNN = pd.read_csv('language_detection-second.csv')\n",
    "\n",
    "# Preprocess the text by converting to a bag-of-words representation\n",
    "vectorizer1 = TfidfVectorizer()\n",
    "E = vectorizer1.fit_transform(dataKNN['Text'])\n",
    "\n",
    "# Convert the target labels to numerical values\n",
    "f = pd.factorize(dataKNN['Language'])[0]\n",
    "\n",
    "# Split to test, train \n",
    "E_train, E_val, f_train, f_val = train_test_split(E, f, test_size=0.2, stratify=y)\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn2 = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn2.fit(E_train, f_train)\n",
    "\n",
    "# Predict the language for each sample in the validation set\n",
    "f_pred = knn2.predict(E_val)\n",
    "\n",
    "\n",
    "\n",
    "# Was having issues witht the transform(), i had to transform the text to be predicted\n",
    "# checking the size of the trained data\n",
    "\n",
    "# print(E_train.shape)\n",
    "# print(E_val.shape)\n",
    "\n",
    "\n",
    "# Create a dictionary that maps numerical labels to language names\n",
    "label_to_language = {0: 'Yoruba', 1: 'Not Yoruba'}\n",
    "\n",
    "\n",
    "# Compute the accuracy of the predictions\n",
    "accuracy = sum(f_pred == f_val) / len(f_val)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2a9c57",
   "metadata": {},
   "source": [
    "### KNN RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35a5ecb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The language of \"Mofẹ́ pààrọ̀ gílóòbù iná\" is Yoruba\n"
     ]
    }
   ],
   "source": [
    "# Predict the language of new text\n",
    "predictText = 'Mofẹ́ pààrọ̀ gílóòbù iná'\n",
    "\n",
    "# sample text = My father is the cousin to England's present Queen, Bonjour, comment allez-vous?\n",
    "\n",
    "language_label = knn2.predict(vectorizer1.transform([predictText]))[0]\n",
    "mainLanguage = label_to_language[language_label]\n",
    "print(f'The language of \"{predictText}\" is {mainLanguage}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3426b0",
   "metadata": {},
   "source": [
    "# ................................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971f80c3",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de0885",
   "metadata": {},
   "source": [
    "\n",
    "### Calculating the Accuracy  of the main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3678b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "483e41e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.38273045507584\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {metrics.accuracy_score(y_test,predict_val)*100}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd35698",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4eb3f691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[329,  14],\n",
       "       [ 17, 497]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test,predict_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d45e1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Not Yoruba'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.predict(['My name is osas']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "906922a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Not Yoruba'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.predict(['cook']) # => Wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b4e7c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if model_pipe.predict(['ílóòbù iná tó wà']) != 'Yoruba' or model_pipe.predict(['Marvelous']) != 'English':\n",
    "#     error = ('Error: Not a yoruba or English text')\n",
    "#     print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fc03ff",
   "metadata": {},
   "source": [
    "### Saving as a pickle file\n",
    "\n",
    "##### to be used on the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03353197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a679f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file = open('model.pckl', 'wb')\n",
    "new_file = open('model.pkl', 'wb')\n",
    "pickle.dump(model_pipe,new_file)\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe28a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c131222",
   "metadata": {},
   "source": [
    "## Thank You!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
